{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_rule_1_tr = pd.read_csv(r\"../artifacts\\data_preprocessing\\BRCA\\ac_rule_1.tsv\", sep=\"\\t\" , header=None , names=[\"label\" , \"support\" , \"confidence\" , \"rules\" , \"interestingness\"])\n",
    "ac_rule_1_te = pd.read_csv(r\"../artifacts\\data_preprocessing\\BRCA\\ac_rule_1_te.tsv\", sep=\"\\t\" , header=None , names=[\"label\" , \"support\" , \"confidence\" , \"rules\" , \"interestingness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tchia\\AppData\\Local\\Temp\\ipykernel_16268\\1642498320.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_top50_tr = ac_rule_1_tr.groupby(\"label\").apply(lambda x: x.nlargest(50, \"interestingness\")).reset_index(drop=True)\n",
      "C:\\Users\\tchia\\AppData\\Local\\Temp\\ipykernel_16268\\1642498320.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_top50_te = ac_rule_1_te.groupby(\"label\").apply(lambda x: x.nlargest(50, \"interestingness\")).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# get top 50 rules based on interestingness for each label \n",
    "grouped_top50_tr = ac_rule_1_tr.groupby(\"label\").apply(lambda x: x.nlargest(50, \"interestingness\")).reset_index(drop=True)\n",
    "grouped_top50_te = ac_rule_1_te.groupby(\"label\").apply(lambda x: x.nlargest(50, \"interestingness\")).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each group and summary the unique antecedent count of the rules\n",
    "class_summary_tr = {}\n",
    "\n",
    "for label in grouped_top50_tr[\"label\"].unique():\n",
    "    filtered = grouped_top50_tr[grouped_top50_tr[\"label\"] == label]\n",
    "    \n",
    "    class_summary_tr[label] = {}\n",
    "    \n",
    "    for idx , row in filtered.iterrows():\n",
    "        antecedents = [x.split(\":\")[0] for x in row[\"rules\"].split(\",\")]\n",
    "        \n",
    "        for antecedent in antecedents:\n",
    "            if antecedent not in class_summary_tr[label]:\n",
    "                class_summary_tr[label][antecedent] = 1\n",
    "            else:\n",
    "                class_summary_tr[label][antecedent] += 1\n",
    "\n",
    "class_summary_te = {}         \n",
    "for label in grouped_top50_te[\"label\"].unique():\n",
    "    filtered = grouped_top50_te[grouped_top50_tr[\"label\"] == label]\n",
    "    \n",
    "    class_summary_te[label] = {}\n",
    "    \n",
    "    for idx , row in filtered.iterrows():\n",
    "        antecedents = [x.split(\":\")[0] for x in row[\"rules\"].split(\",\")]\n",
    "        \n",
    "        for antecedent in antecedents:\n",
    "            if antecedent not in class_summary_te[label]:\n",
    "                class_summary_te[label][antecedent] = 1\n",
    "            else:\n",
    "                class_summary_te[label][antecedent] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | Class 0.0 has 174 unique antecedents\n",
      "Train | Class 1.0 has 719 unique antecedents\n",
      "Train | Class 2.0 has 647 unique antecedents\n",
      "Train | Class 3.0 has 511 unique antecedents\n",
      "Train | Class 4.0 has 871 unique antecedents\n",
      "Train | Class 0.0 has 242 unique antecedents\n",
      "Train | Class 1.0 has 840 unique antecedents\n",
      "Train | Class 2.0 has 616 unique antecedents\n",
      "Train | Class 3.0 has 486 unique antecedents\n",
      "Train | Class 4.0 has 959 unique antecedents\n"
     ]
    }
   ],
   "source": [
    "# print the summary\n",
    "for key in class_summary_tr.keys():\n",
    "    print(f\"Train | Class {key} has {len(class_summary_tr[key].keys())} unique antecedents\")\n",
    "    \n",
    "for key in class_summary_te.keys():\n",
    "    print(f\"Train | Class {key} has {len(class_summary_te[key].keys())} unique antecedents\")\n",
    "    \n",
    "# print common antecedents between classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(class_summary_te[2.0].values()).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 has 123 common antecedents between train and test\n",
      "Class 1.0 has 635 common antecedents between train and test\n",
      "Class 2.0 has 505 common antecedents between train and test\n",
      "Class 3.0 has 344 common antecedents between train and test\n",
      "Class 4.0 has 845 common antecedents between train and test\n",
      "\n",
      "Class 0.0 : [0, 12, 2, 3, 12]\n",
      "Class 1.0 : [62, 0, 78, 83, 68]\n",
      "Class 2.0 : [10, 62, 0, 77, 55]\n",
      "Class 3.0 : [10, 45, 52, 0, 36]\n",
      "Class 4.0 : [86, 90, 92, 90, 0]\n",
      "\n",
      "Class 0.0 : [0, 77, 13, 13, 106]\n",
      "Class 1.0 : [77, 0, 398, 286, 576]\n",
      "Class 2.0 : [13, 398, 0, 266, 468]\n",
      "Class 3.0 : [13, 286, 266, 0, 310]\n",
      "Class 4.0 : [106, 576, 468, 310, 0]\n"
     ]
    }
   ],
   "source": [
    "intersection_genes_set = {}\n",
    "for key in class_summary_tr.keys():\n",
    "    # find intersection between classes\n",
    "    intersection = set(class_summary_tr[key].keys()).intersection(class_summary_te[key].keys())\n",
    "    print(f\"Class {key} has {len(intersection)} common antecedents between train and test\")\n",
    "    intersection_genes_set[key] = intersection\n",
    "    \n",
    "print()\n",
    "# print the common antecedents among the classes \n",
    "for key in intersection_genes_set.keys():\n",
    "    print(f\"Class {key} : {[ 0 if x == key else int(len(intersection_genes_set[x].intersection(intersection_genes_set[key]))/len(intersection_genes_set[x])*100)  for x in intersection_genes_set.keys() ]}\")\n",
    "    \n",
    "# print the common antecedents among the classes \n",
    "print()\n",
    "for key in intersection_genes_set.keys():\n",
    "    print(f\"Class {key} : {[ 0 if x == key else len(intersection_genes_set[x].intersection(intersection_genes_set[key])) for x in intersection_genes_set.keys() ]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = pd.read_csv(r\"../artifacts\\data_preprocessing\\BRCA\\labels_te.csv\", sep=\"\\t\" , header=None)\n",
    "tr = pd.read_csv(r\"../artifacts\\data_preprocessing\\BRCA\\labels_tr.csv\", sep=\"\\t\" , header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0     44\n",
      "1.0     10\n",
      "2.0    122\n",
      "3.0     45\n",
      "4.0     10\n",
      "dtype: int64\n",
      "0\n",
      "0.0     86\n",
      "1.0     36\n",
      "2.0    297\n",
      "3.0     95\n",
      "4.0     24\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(te.groupby(0).size())\n",
    "print(tr.groupby(0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle file KBinsDiscretizer\n",
    "import pickle\n",
    "\n",
    "with open(r\"../artifacts\\data_preprocessing\\BRCA\\kbins_1.joblib\", \"rb\") as file:\n",
    "    est = pickle.load(file)\n",
    "    \n",
    "# load test data\n",
    "omic_1_te = pd.read_csv(r\"../artifacts\\data_preprocessing\\BRCA\\1_te.csv\", header=None)\n",
    "# Discritize the test data\n",
    "omic_1_te = pd.DataFrame(est.transform(omic_1_te) , columns=omic_1_te.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_model = {}\n",
    "\n",
    "for label in grouped_top50_te[\"label\"].unique():\n",
    "    filtered = grouped_top50_te[grouped_top50_te[\"label\"] == label]\n",
    "    \n",
    "    testing_model[label] = []\n",
    "    \n",
    "    for idx , row in filtered.iterrows():\n",
    "        rules = set(row[\"rules\"].split(\",\"))\n",
    "        testing_model[label].append(rules)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classification_summary = []\n",
    "for idx , row in omic_1_te.iterrows():\n",
    "    # test each rules \n",
    "    sample = set([f\"{x[0]}:{x[1]}\" for x in list(zip(row.index , row.values))])\n",
    "    # print(sample)\n",
    "    # print(testing_model[0.0][0])\n",
    "    # print(len(testing_model[0.0][0].intersection(sample)))\n",
    "    # print(len(testing_model[0.0][0]))\n",
    "    summary = {}\n",
    "    for label in testing_model.keys():\n",
    "        summary[label] = []\n",
    "        \n",
    "        for rule in testing_model[label]:\n",
    "            insersection_set = rule.intersection(sample)\n",
    "            summary[label].append(len(insersection_set)/len(rule))\n",
    "            \n",
    "        summary[label] = np.mean(summary[label])\n",
    "    \n",
    "    # select max value key\n",
    "    summary['prediction'] = max(summary, key=summary.get)\n",
    "    summary['sample'] = idx\n",
    "    classification_summary.append(summary)\n",
    "    #print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984438</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>0.962903</td>\n",
       "      <td>0.964840</td>\n",
       "      <td>0.957914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986221</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997803</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.897539</td>\n",
       "      <td>0.975734</td>\n",
       "      <td>0.998172</td>\n",
       "      <td>0.997803</td>\n",
       "      <td>0.983642</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.979400</td>\n",
       "      <td>0.991205</td>\n",
       "      <td>0.998172</td>\n",
       "      <td>0.997803</td>\n",
       "      <td>0.994531</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979266</td>\n",
       "      <td>0.980019</td>\n",
       "      <td>0.988816</td>\n",
       "      <td>0.997803</td>\n",
       "      <td>0.976421</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.994021</td>\n",
       "      <td>0.938194</td>\n",
       "      <td>0.921334</td>\n",
       "      <td>0.937436</td>\n",
       "      <td>0.937757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.917734</td>\n",
       "      <td>0.981056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995605</td>\n",
       "      <td>0.985830</td>\n",
       "      <td>2.0</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.958529</td>\n",
       "      <td>0.987735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.986391</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.992773</td>\n",
       "      <td>0.989196</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.997803</td>\n",
       "      <td>0.996630</td>\n",
       "      <td>2.0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.828398</td>\n",
       "      <td>0.957167</td>\n",
       "      <td>0.994480</td>\n",
       "      <td>0.990332</td>\n",
       "      <td>0.963890</td>\n",
       "      <td>2.0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.0       1.0       2.0       3.0       4.0  prediction  sample\n",
       "0    0.984438  0.972336  0.962903  0.964840  0.957914         0.0       0\n",
       "1    0.986221  0.994100  1.000000  0.997803  0.998516         2.0       1\n",
       "2    0.897539  0.975734  0.998172  0.997803  0.983642         2.0       2\n",
       "3    0.979400  0.991205  0.998172  0.997803  0.994531         2.0       3\n",
       "4    0.979266  0.980019  0.988816  0.997803  0.976421         3.0       4\n",
       "..        ...       ...       ...       ...       ...         ...     ...\n",
       "226  0.994021  0.938194  0.921334  0.937436  0.937757         0.0     226\n",
       "227  0.917734  0.981056  1.000000  0.995605  0.985830         2.0     227\n",
       "228  0.958529  0.987735  1.000000  0.999912  0.986391         2.0     228\n",
       "229  0.992773  0.989196  0.999927  0.997803  0.996630         2.0     229\n",
       "230  0.828398  0.957167  0.994480  0.990332  0.963890         2.0     230\n",
       "\n",
       "[231 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = pd.DataFrame(classification_summary)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv(r\"..\\artifacts\\data_preprocessing\\BRCA\\labels_te.csv\" , header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.91      0.88        44\n",
      "         1.0       1.00      0.60      0.75        10\n",
      "         2.0       0.86      0.96      0.91       122\n",
      "         3.0       0.89      0.76      0.82        45\n",
      "         4.0       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.87       231\n",
      "   macro avg       0.87      0.70      0.76       231\n",
      "weighted avg       0.87      0.87      0.86       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(label , df_prediction[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
