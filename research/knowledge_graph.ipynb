{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "emb_1 = torch.load(r\"..\\artifacts\\train_embedding\\BRCA\\1_embedding.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#string_protein_id</th>\n",
       "      <th>preferred_name</th>\n",
       "      <th>protein_size</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>180</td>\n",
       "      <td>ADP-ribosylation factor 5; GTP-binding protein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9606.ENSP00000000412</td>\n",
       "      <td>M6PR</td>\n",
       "      <td>277</td>\n",
       "      <td>Cation-dependent mannose-6-phosphate receptor;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9606.ENSP00000001008</td>\n",
       "      <td>FKBP4</td>\n",
       "      <td>459</td>\n",
       "      <td>Peptidyl-prolyl cis-trans isomerase FKBP4, N-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9606.ENSP00000001146</td>\n",
       "      <td>CYP26B1</td>\n",
       "      <td>512</td>\n",
       "      <td>Cytochrome P450 26B1; Involved in the metaboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9606.ENSP00000002125</td>\n",
       "      <td>NDUFAF7</td>\n",
       "      <td>441</td>\n",
       "      <td>Protein arginine methyltransferase NDUFAF7, mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #string_protein_id preferred_name  protein_size  \\\n",
       "0  9606.ENSP00000000233           ARF5           180   \n",
       "1  9606.ENSP00000000412           M6PR           277   \n",
       "2  9606.ENSP00000001008          FKBP4           459   \n",
       "3  9606.ENSP00000001146        CYP26B1           512   \n",
       "4  9606.ENSP00000002125        NDUFAF7           441   \n",
       "\n",
       "                                          annotation  \n",
       "0  ADP-ribosylation factor 5; GTP-binding protein...  \n",
       "1  Cation-dependent mannose-6-phosphate receptor;...  \n",
       "2  Peptidyl-prolyl cis-trans isomerase FKBP4, N-t...  \n",
       "3  Cytochrome P450 26B1; Involved in the metaboli...  \n",
       "4  Protein arginine methyltransferase NDUFAF7, mi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load knowlege link and information \n",
    "\n",
    "df_protein = pd.read_csv(r\"..\\PPI\\9606.protein.info.v12.0.txt\", sep=\"\\t\")\n",
    "\n",
    "df_protein.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tchia\\AppData\\Local\\Temp\\ipykernel_13064\\4158430.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_protein_link = pd.read_csv(r\"..\\PPI\\9606.protein.links.v12.0.txt\", sep=\"\\s\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13715404, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>protein2</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000356607</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000427567</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000253413</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000493357</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000324127</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               protein1              protein2  combined_score\n",
       "0  9606.ENSP00000000233  9606.ENSP00000356607             173\n",
       "1  9606.ENSP00000000233  9606.ENSP00000427567             154\n",
       "2  9606.ENSP00000000233  9606.ENSP00000253413             151\n",
       "3  9606.ENSP00000000233  9606.ENSP00000493357             471\n",
       "4  9606.ENSP00000000233  9606.ENSP00000324127             201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_link = pd.read_csv(r\"..\\PPI\\9606.protein.links.v12.0.txt\", sep=\"\\s\")\n",
    "print(df_protein_link.shape)\n",
    "df_protein_link.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_score</th>\n",
       "      <th>protein1_name</th>\n",
       "      <th>protein2_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>RALGPS2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>FHDC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>ATP6V1E1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>CYTH2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>PSD3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   combined_score protein1_name protein2_name\n",
       "0             173          ARF5       RALGPS2\n",
       "1             154          ARF5         FHDC1\n",
       "2             151          ARF5      ATP6V1E1\n",
       "3             471          ARF5         CYTH2\n",
       "4             201          ARF5          PSD3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_merged = pd.merge(df_protein_link, df_protein[['#string_protein_id','preferred_name']], left_on=\"protein1\", right_on=\"#string_protein_id\")\n",
    "df_protein_merged.rename(columns={\"preferred_name\":\"protein1_name\"}, inplace=True)\n",
    "\n",
    "df_protein_merged = pd.merge(df_protein_merged, df_protein[['#string_protein_id','preferred_name']], left_on=\"protein2\", right_on=\"#string_protein_id\")\n",
    "df_protein_merged.rename(columns={\"preferred_name\":\"protein2_name\"}, inplace=True)\n",
    "\n",
    "# drop columns\n",
    "df_protein_merged.drop(columns=[\"#string_protein_id_x\", \"#string_protein_id_y\", \"protein1\" , \"protein2\"], inplace=True)\n",
    "df_protein_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_idx</th>\n",
       "      <th>0</th>\n",
       "      <th>gene_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ABAT|18</td>\n",
       "      <td>ABAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABCF1|23</td>\n",
       "      <td>ABCF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ABCF2|10061</td>\n",
       "      <td>ABCF2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACOT4|122970</td>\n",
       "      <td>ACOT4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACOT9|23597</td>\n",
       "      <td>ACOT9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene_idx             0 gene_name\n",
       "0         0       ABAT|18      ABAT\n",
       "1         1      ABCF1|23     ABCF1\n",
       "2         2   ABCF2|10061     ABCF2\n",
       "3         3  ACOT4|122970     ACOT4\n",
       "4         4   ACOT9|23597     ACOT9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load omic data header 1\n",
    "df_omic_1 = pd.read_csv(r\"..\\artifacts\\data_preprocessing\\BRCA\\1_featname.csv\",header=None)\n",
    "df_omic_1['gene_name'] = df_omic_1[0].apply(lambda x: x.split(\"|\")[0])\n",
    "df_omic_1 = df_omic_1.index.to_frame(name=\"gene_idx\").join(df_omic_1)\n",
    "\n",
    "print(df_omic_1.shape)\n",
    "df_omic_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_score</th>\n",
       "      <th>protein1_name</th>\n",
       "      <th>protein2_name</th>\n",
       "      <th>gene1_idx</th>\n",
       "      <th>gene2_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>RALGPS2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>723.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>FHDC1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>ATP6V1E1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>CYTH2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>PSD3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   combined_score protein1_name protein2_name  gene1_idx  gene2_idx\n",
       "0             173          ARF5       RALGPS2        NaN      723.0\n",
       "1             154          ARF5         FHDC1        NaN        NaN\n",
       "2             151          ARF5      ATP6V1E1        NaN        NaN\n",
       "3             471          ARF5         CYTH2        NaN        NaN\n",
       "4             201          ARF5          PSD3        NaN        NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load omic data header 2\n",
    "df_protein_merged = df_protein_merged.merge(df_omic_1[['gene_idx' , 'gene_name']] , left_on=\"protein1_name\", right_on=\"gene_name\" , how=\"left\")\n",
    "df_protein_merged.rename(columns={\"gene_idx\":\"gene1_idx\"}, inplace=True)\n",
    "\n",
    "df_protein_merged = df_protein_merged.merge(df_omic_1[['gene_idx' , 'gene_name']] , left_on=\"protein2_name\", right_on=\"gene_name\" , how=\"left\")\n",
    "df_protein_merged.rename(columns={\"gene_idx\":\"gene2_idx\"}, inplace=True)\n",
    "\n",
    "df_protein_merged.drop(columns=[\"gene_name_x\", \"gene_name_y\"], inplace=True)\n",
    "\n",
    "df_protein_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tchia\\AppData\\Local\\Temp\\ipykernel_13064\\2743917618.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_filter_protein = df_protein_merged[df_protein_merged['gene1_idx'].notnull()][df_protein_merged['gene2_idx'].notnull()]\n"
     ]
    }
   ],
   "source": [
    "# filter rows with only gene1_idx and gene2_idx\n",
    "df_filter_protein = df_protein_merged[df_protein_merged['gene1_idx'].notnull()][df_protein_merged['gene2_idx'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/90654 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90654/90654 [00:11<00:00, 7663.99it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "knowledge_tensor = torch.zeros(1000 , 1000)\n",
    "with tqdm(total=df_filter_protein.shape[0]) as pbar:\n",
    "    for idx , row in df_filter_protein.iterrows():\n",
    "        knowledge_tensor[int(row['gene1_idx']) , int(row['gene2_idx'])] += 1\n",
    "        #knowledge_tensor[int(row['gene2_idx']) , int(row['gene1_idx'])] += 1\n",
    "        pbar.update(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1000, 128], edge_index=[2, 90654], edge_attr=[90654, 1], num_nodes=1000)\n"
     ]
    }
   ],
   "source": [
    "from amogel.utils.common import symmetric_matrix_to_coo , coo_to_pyg_data\n",
    "coo_matrix = symmetric_matrix_to_coo(knowledge_tensor.numpy() , 1)\n",
    "graph = coo_to_pyg_data(coo_matrix=coo_matrix , node_features=emb_1)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:03<00:00, 183.82it/s]\n",
      "100%|██████████| 154/154 [00:00<00:00, 199.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# load the sample \n",
    "df_label_train  = pd.read_csv(r\"..\\artifacts\\data_preprocessing\\BRCA\\labels_tr.csv\", header=None)\n",
    "df_label_test   = pd.read_csv(r\"..\\artifacts\\data_preprocessing\\BRCA\\labels_te.csv\", header=None)\n",
    "\n",
    "df = pd.read_csv(r\"../artifacts/data_preprocessing/BRCA/1_tr.csv\", header=None)\n",
    "graphs_training = []\n",
    "with tqdm(total=df.shape[0]) as pbar:\n",
    "    for idx , sample in df.iterrows():\n",
    "        torch_sample = torch.tensor(sample.values, dtype=torch.float32).unsqueeze(-1)\n",
    "        node_embedding = torch.concat([torch_sample , emb_1] , dim=-1)\n",
    "        graph = coo_to_pyg_data(coo_matrix=coo_matrix , node_features=node_embedding , y = torch.tensor(df_label_train.iloc[idx].values , dtype=torch.long) )\n",
    "        graphs_training.append(graph)\n",
    "        pbar.update(1)\n",
    "        \n",
    "\n",
    "graphs_testing = []\n",
    "df = pd.read_csv(r\"../artifacts/data_preprocessing/BRCA/1_te.csv\", header=None)\n",
    "with tqdm(total=df.shape[0]) as pbar:\n",
    "    for idx , sample in df.iterrows():\n",
    "        torch_sample = torch.tensor(sample.values, dtype=torch.float32).unsqueeze(-1)\n",
    "        node_embedding = torch.concat([torch_sample , emb_1] , dim=-1)\n",
    "        graph = coo_to_pyg_data(coo_matrix=coo_matrix , node_features=node_embedding , y = torch.tensor(df_label_test.iloc[idx].values , dtype=torch.long))\n",
    "        graphs_testing.append(graph)\n",
    "        pbar.update(1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1000, 129], edge_index=[2, 90654], edge_attr=[90654, 1], y=[1], num_nodes=1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-18 22:19:01,313: INFO: setup: GPU available: False, used: False]\n",
      "[2024-04-18 22:19:01,314: INFO: setup: TPU available: False, using: 0 TPU cores]\n",
      "[2024-04-18 22:19:01,315: INFO: setup: IPU available: False, using: 0 IPUs]\n",
      "[2024-04-18 22:19:01,315: INFO: setup: HPU available: False, using: 0 HPUs]\n",
      "[2024-04-18 22:19:01,321: INFO: model_summary: \n",
      "   | Name      | Type                      | Params\n",
      "---------------------------------------------------------\n",
      "0  | conv1     | GCNConv                   | 8.3 K \n",
      "1  | bn1       | BatchNorm                 | 128   \n",
      "2  | conv2     | GCNConv                   | 4.2 K \n",
      "3  | bn2       | BatchNorm                 | 128   \n",
      "4  | conv3     | GCNConv                   | 4.2 K \n",
      "5  | lin       | Linear                    | 325   \n",
      "6  | criterion | CrossEntropyLoss          | 0     \n",
      "7  | accuracy  | MulticlassAccuracy        | 0     \n",
      "8  | precision | MulticlassPrecision       | 0     \n",
      "9  | recall    | MulticlassRecall          | 0     \n",
      "10 | auroc     | MulticlassAUROC           | 0     \n",
      "11 | cfm       | MulticlassConfusionMatrix | 0     \n",
      "---------------------------------------------------------\n",
      "17.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.2 K    Total params\n",
      "0.069     Total estimated model params size (MB)]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tchia\\miniconda3\\envs\\gnn\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  0.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tchia\\miniconda3\\envs\\gnn\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:03<00:00,  0.51it/s]\n",
      "-------- Confusion Matrix [Testing] --------\n",
      "[[ 0  0  0  0  8]\n",
      " [ 0  0  0  0  2]\n",
      " [ 0  0  0  0 38]\n",
      " [ 0  0  0  0 15]\n",
      " [ 0  0  0  0  1]]\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tchia\\miniconda3\\envs\\gnn\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\tchia\\miniconda3\\envs\\gnn\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [01:04<00:00,  0.31it/s, v_num=19, train_loss=1.550, train_acc=0.429] \n",
      "-------- Confusion Matrix [Testing] --------\n",
      "[[  0   2  57   3  68]\n",
      " [  0   0  21   1  24]\n",
      " [  6   4 193  20 196]\n",
      " [  2   1  77   4  56]\n",
      " [  0   0  20   0  14]]\n",
      "Epoch 0: 100%|██████████| 20/20 [01:15<00:00,  0.26it/s, v_num=19, train_loss=1.550, train_acc=0.429, val_loss=1.550, val_acc=0.545, val_preci=0.545, val_rec=0.545, val_auroc=0.486]\n",
      "-------- Confusion Matrix [Training] --------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "Epoch 1:   0%|          | 0/20 [00:00<?, ?it/s, v_num=19, train_loss=1.550, train_acc=0.429, val_loss=1.550, val_acc=0.545, val_preci=0.545, val_rec=0.545, val_auroc=0.486]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tchia\\miniconda3\\envs\\gnn\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric MulticlassConfusionMatrix was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 20/20 [01:15<00:00,  0.27it/s, v_num=19, train_loss=1.480, train_acc=0.571, val_loss=1.550, val_acc=0.545, val_preci=0.545, val_rec=0.545, val_auroc=0.486]\n",
      "-------- Confusion Matrix [Testing] --------\n",
      "[[  1   0  98   4  27]\n",
      " [  0   0  32   1  13]\n",
      " [  2   0 324  16  77]\n",
      " [  1   1 108   6  24]\n",
      " [  0   0  24   1   9]]\n",
      "Epoch 1: 100%|██████████| 20/20 [01:25<00:00,  0.23it/s, v_num=19, train_loss=1.480, train_acc=0.571, val_loss=1.530, val_acc=0.545, val_preci=0.545, val_rec=0.545, val_auroc=0.531]\n",
      "-------- Confusion Matrix [Training] --------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "Epoch 2:  65%|██████▌   | 13/20 [00:57<00:30,  0.23it/s, v_num=19, train_loss=1.540, train_acc=0.469, val_loss=1.530, val_acc=0.545, val_preci=0.545, val_rec=0.545, val_auroc=0.531]"
     ]
    }
   ],
   "source": [
    "# build simple GCN model for graph classification \n",
    "from torch_geometric.loader import DataLoader   \n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy , Precision , Recall , AUROC , ConfusionMatrix\n",
    "\n",
    "train_loader = DataLoader(graphs_training, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(graphs_testing, batch_size=32, shuffle=False)\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv , BatchNorm \n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GCN(pl.LightningModule):\n",
    "    def __init__(self, num_features ,  hidden_channels , output_class):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.bn1 = BatchNorm(hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.bn2 = BatchNorm(hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, output_class)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=output_class)\n",
    "        self.precision = Precision(task=\"multiclass\" , num_classes=output_class)\n",
    "        self.recall = Recall(task=\"multiclass\" , num_classes=output_class)\n",
    "        self.auroc = AUROC(task=\"multiclass\" ,num_classes=output_class)\n",
    "        self.cfm_training = ConfusionMatrix(task=\"multiclass\", num_classes=output_class)\n",
    "        self.cfm_testing = ConfusionMatrix(task=\"multiclass\", num_classes=output_class)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x , edge_index , batch , y = batch.x , batch.edge_index , batch.batch , batch.y\n",
    "        out = self(x, edge_index, batch)\n",
    "        loss = self.criterion(out, y)\n",
    "        acc = self.accuracy(out, y)\n",
    "        self.cfm_training(out , y)\n",
    "        \n",
    "        self.log('train_loss' , loss , prog_bar=True)\n",
    "        self.log('train_acc' , acc , prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x , edge_index , batch , y = batch.x , batch.edge_index , batch.batch , batch.y\n",
    "        out = self(x, edge_index, batch)\n",
    "        loss = self.criterion(out, y)\n",
    "        acc = self.accuracy(out, y)\n",
    "        preci = self.precision(out, y)\n",
    "        rec = self.recall(out, y)\n",
    "        auroc = self.auroc(out, y)\n",
    "        cfm = self.cfm_testing(out, y)  \n",
    "        \n",
    "        self.log('val_loss' , loss , prog_bar=True, on_epoch=True)\n",
    "        self.log('val_acc' , acc , prog_bar=True, on_epoch=True)\n",
    "        self.log('val_preci' , preci , prog_bar=True, on_epoch=True)\n",
    "        self.log('val_rec' , rec , prog_bar=True, on_epoch=True)\n",
    "        self.log('val_auroc' , auroc , prog_bar=True , on_epoch=True)\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        \n",
    "        cfm = self.cfm_training.compute().cpu().numpy()\n",
    "        print(\"\")\n",
    "        print(\"-------- Confusion Matrix [Training] --------\")\n",
    "        print(cfm)\n",
    "        \n",
    "        self.cfm_training.reset()\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        cfm = self.cfm_testing.compute().cpu().numpy()\n",
    "        print(\"\")\n",
    "        print(\"-------- Confusion Matrix [Testing] --------\")\n",
    "        print(cfm)\n",
    "        \n",
    "        self.cfm_testing.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "model = GCN(num_features=129 , hidden_channels=64 , output_class=5)\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
